{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 670 :: Information Storage and Retrieval :: Spring 2020\n",
    "\n",
    "# Visdom - a AI training virtualization tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visdom is a virtualization tool for pytorch which developed by FACEBOOK Artificial Intelligence. It can be used to create, organize, and share real-time, rich data. Support Torch and Numpy and pytorch. Visdom realize the visualization of remote data, which is very helpful for scientific experiments. We can send pictures and data remotely and display them on the UI interface to check the experimental results or debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some views show how visdom looks like when you train a machine learning and monitor the training using visdom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"visdom_chart.jpg\" style=\"width: 500px;\">\n",
    "<img src=\"visdom_main.jpg\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "Python3 is required\n",
    "\n",
    "`pip install visdom`\n",
    "\n",
    "or\n",
    "\n",
    "`conda install -c conda-forge visdom` if using Anaconda\n",
    "\n",
    "### Test if visdom is successfully installed\n",
    "\n",
    "Run `visdom` or `python -m visdom.server` on command-line.\n",
    "If it's successfully installed, the screen should look like this.\n",
    "<img src=\"run_visdom.png\" style=\"width: 500px;\">\n",
    "\n",
    "Now you can visit the url presented on the terminal, but it should be blank at first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "### Panes: \n",
    "The interface is blank when first opening it. Transmitting plots and charts to backend can make it generate panes. Panes can be dragged, resized or deleted. Take the picture above for example, there are 12 generated panes, each with different chart type and style.\n",
    "\n",
    "<img src=\"visdom_blank.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Environment: \n",
    "envs can divid a visualization space into groups. The visual results of different environments are isolated from each other and do not affect each other. If you do not specify env when using it, the default is to use main. Different users and different programs generally use different env.\n",
    "\n",
    "<img src=\"envs.png\" style=\"height: 100px;\">\n",
    "\n",
    "#### Select environments\n",
    "You can select a environment from the bar on the top of the visdom page.\n",
    "\n",
    "#### Erase Environments\n",
    "On the bar of the visdom page, there's a erase button. Click on the erase button can clean out the whole content of the current environment. For preventing accidently clicks, it would ask you to confirm again after pressing the button.\n",
    "\n",
    "#### Save Environments\n",
    "Click the save button(near the erase button) to save the current env as a json file. The storage path is located in the ~ / .visdom / directory. You can also modify the name of the env and click fork to save the current env status to the renamed env.\n",
    "\n",
    "### State: \n",
    "\n",
    "When you put graphs on the server, the server would cache those graph. So, if a user turn off the server and turn on it again, the graphs would still be there.\n",
    "\n",
    "There are two points to note when using Visdom:\n",
    "1. You need to manually specify the save env. For example, `vis.text('Hello, world!', env=\"main\")`\n",
    "you can click the save button on the web interface or call the save method in the program, otherwise the env and other information will be lost after the visdom service restarts\n",
    "2. The interaction between the client and the server uses the tornado asynchronous framework, and the visual operation will not block the current program, and network abnormalities will not cause the program to exit.\n",
    "\n",
    "\n",
    "### Drawing Functions\n",
    "Visdom has several common drawing functions, such as:\n",
    "\n",
    "-line: Similar to the 'plot' operation in Matlab, used to record changes of certain scalars, such as loss, accuracy, etc.\n",
    "\n",
    "-image: Visualized image, which can be the input image, the image generated by GAN, or the information of the convolution kernel\n",
    "\n",
    "-text: Used to record text information such as logs, supports html format\n",
    "\n",
    "-scatter: Draw a scatter plotbar: draw a bar chart\n",
    "\n",
    "-bar: Draw a bar chart\n",
    "\n",
    "-pie: Draw a pie chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the server from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`visdom`\n",
    "\n",
    "or\n",
    "\n",
    "`visdom -m visdom.server`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-Line Options\n",
    "The following options can be provided to the server:\n",
    "\n",
    "`-port`: The port to run the server on.\n",
    "\n",
    "`-hostname` : The hostname to run the server on.\n",
    "\n",
    "`-base_url` : The base server url (default = /).\n",
    "\n",
    "`-env_path` : The path to the serialized session to reload.\n",
    "\n",
    "`-logging_level` : Logging level (default = INFO). Accepts both standard text and numeric logging values.\n",
    "\n",
    "`-readonly` : Flag to start server in readonly mode.\n",
    "\n",
    "`-enable_login` : Flag to setup authentication for the sever, requiring a username and password to login.\n",
    "\n",
    "`-force_new_cookie` : Flag to reset the secure cookie used by the server, invalidating current login cookies.\n",
    "Requires -enable_login."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "#need to start visdom server in the commandline first\n",
    "\n",
    "import visdom\n",
    "import numpy as np\n",
    "import math\n",
    "vis = visdom.Visdom(env=\"main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_385cc637d7ba2c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vis.text\n",
    "vis.text('Hello, world!', opts=dict(title=\"text\", env=\"main\"))\n",
    "\n",
    "#vis.image\n",
    "vis.image(np.random.rand(3, 256, 256), opts=dict(title=\"random_image\"))\n",
    "\n",
    "#vis.pie\n",
    "vis.pie(np.asarray([35, 25, 40]), opts=dict(title=\"pie\", legend=[\"Front-End Engineer\", \"Back-End Engineer\", \"Machine Learning Engineer\"]))\n",
    "\n",
    "#vis.bar\n",
    "vis.bar(np.random.rand(10), opts=dict(title=\"bar\"))\n",
    "\n",
    "#vis.line\n",
    "vis.line(np.random.rand(10), opts=dict(title=\"line\"))\n",
    "\n",
    "#vis.stem\n",
    "Y = np.linspace(0, 2 * math.pi, 70)\n",
    "X = np.column_stack((np.sin(Y), np.cos(Y)))\n",
    "vis.stem(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    opts=dict(title=\"stem\", legend=['Sine', 'Cosine'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can check the page on visdom, there should be several panes on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use visdom to monitor the training loss, testing loss and accuracy of a CNN, the CNN is in charge of identifying the digital numbers in MNIST dataset. The visdom figures update in each epoch. Notice that here we use `update='append'` in `vis.line()`, otherwise it would override the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.299417\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 2.285022\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 2.259548\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 4480.0/10000 (45%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.228044\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.160003\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.076617\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 4833.0/10000 (48%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.984172\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.816321\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.700139\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 6043.0/10000 (60%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.519780\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.374087\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.235020\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 6418.0/10000 (64%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.103241\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.180342\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.058966\n",
      "\n",
      "Test set: Average loss: 0.0053, Accuracy: 6524.0/10000 (65%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.086491\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.138929\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.989949\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 7381.0/10000 (74%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.017130\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.880298\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.657643\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 8394.0/10000 (84%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.595367\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.662703\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.617094\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 8737.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.422240\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.418959\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.525032\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8832.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.394866\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.517475\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.412582\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 8897.0/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from visdom import Visdom\n",
    "\n",
    "batch_size = 200\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   # transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 200),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "net = MLP().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "criteon = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "viz = Visdom(env=\"MNIST\")\n",
    "viz.line([0.], [0.], win='train_loss', opts=dict(title='train loss'))\n",
    "viz.line([[0.0, 0.0]], [0.], win='test', opts=dict(title='test loss&acc.', legend=['loss', 'acc.']))\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        data, target = data.to(device), target.cuda()\n",
    "\n",
    "        logits = net(data)\n",
    "        loss = criteon(logits, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # print(w1.grad.norm(), w2.grad.norm())\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "        viz.line([loss.item()], [global_step], win='train_loss', update='append')\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        data, target = data.to(device), target.cuda()\n",
    "        logits = net(data)\n",
    "        test_loss += criteon(logits, target).item()\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += pred.eq(target).float().sum().item()\n",
    "\n",
    "    viz.line([[test_loss, correct / len(test_loader.dataset)]],\n",
    "             [global_step], win='test', update='append')\n",
    "    viz.images(data.view(-1, 1, 28, 28), win='x')\n",
    "    viz.text(str(pred.detach().cpu().numpy()), win='pred',\n",
    "             opts=dict(title='pred'))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NN_result.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://github.com/facebookresearch/visdom\n",
    "2. https://ai.facebook.com/tools/visdom/\n",
    "3. https://blog.csdn.net/SHU15121856/article/details/88818539\n",
    "4. https://zhuanlan.zhihu.com/p/34692106\n",
    "5. https://github.com/noagarcia/visdom-tutorial\n",
    "6. https://udacity.github.io/udacidrone/docs/tutorial-visdom.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
