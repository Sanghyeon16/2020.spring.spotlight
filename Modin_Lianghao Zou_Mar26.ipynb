{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modin\n",
    "### 1. What is Modin \n",
    "Nowadays, information retrieval in industry usually deals with data with high dimension and large scale. Traditionally, the classic library `pandas` would be used to process the data, however, it has been a pain to many researchers that when the size of datasets reaches TB, the `pandas` would become unbearably slow. This may result from the fact `pandas` is designed as single-thread. If you consider how many cores there are in 1 CPU, you will find it is a huge waste of resources. Therefore `Modin` is developed to address this situation.\n",
    "> Modin is an early-stage project at [UC Berkeley's RISELab](https://rise.cs.berkeley.edu/) designed to facilitate the use of distributed computing for Data Science. It is a multipprocess Dataframe library with an **identical API to pandas** that allows users to speed up their Pandas workflows.\n",
    "\n",
    "### 2. Pandas vs. Modin\n",
    "The `modin.pandas` DataFrame is an extremely light-weight parallel DataFrame. In `pandas` you can use only one core at a time. `Modin` currently is using `Ray` and `Dask` as computation engine in the backend to achieve parallel computing. \n",
    "The `Modin` utilized the simple Mapreduce concept to achieve such a goal. To implement, the `Modin` DataFrame architecture follows in the footsteps of modern architectures for database and high performance matrix systems. We choose schema that partitions along both columns and rows because it gives `Modin` flexibility and scalability in both the number of columns and the number of rows supported. The following figure illustrates this concept. ModinDataFrame would be partitioned both in rows and columns and distributed to different CPU.\n",
    "In a 4-core machine, the speed would be 4 time faster with `read_csv` function.\n",
    "![read_csv test](https://modin.readthedocs.io/en/latest/_images/read_csv_benchmark.png)\n",
    "\n",
    "### 3. Architecture\n",
    "#### 3.1 DataFrame Partitioning\n",
    "`Modin` partitions data along both columns and rows because it gives `Modin` flexibility and scalability in both the number of columns and the number of rows supported. For example, for a skewed dataset with few rows but many columns, most existing libraries which partition along columns would find it tricky to partition such data. ![comparision between pandas and modin](https://miro.medium.com/max/1000/0*GYnWlFf7QyueGWEm.png)\n",
    "\n",
    "#### 3.2 System Architecture\n",
    "`Modin` is separated into different layers.`Pandas` API is exposed at the topmost layer. Then it is a layer called Query Compiler which receives queries from the `pandas` API layer and optimize them in a certain way. At the bottom is the partition manager and is responsible for the data layout and shuffling, partitioning and serializing the tasks. ![architecture of Modin](https://miro.medium.com/max/753/0*cOcYOJ3Lib0_04Ji.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How to use Modin\n",
    "#### 4.1 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in e:\\anaconda\\lib\\site-packages (1.18.2)\n",
      "Requirement already satisfied: modin in e:\\anaconda\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from modin) (17.1)\n",
      "Requirement already satisfied: pandas==1.0.1 in e:\\anaconda\\lib\\site-packages (from modin) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\anaconda\\lib\\site-packages (from packaging->modin) (2.2.0)\n",
      "Requirement already satisfied: six in e:\\anaconda\\lib\\site-packages (from packaging->modin) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin) (2018.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin) (1.18.2)\n",
      "Requirement already satisfied: modin[dask] in e:\\anaconda\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: pandas==1.0.1 in e:\\anaconda\\lib\\site-packages (from modin[dask]) (1.0.1)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from modin[dask]) (17.1)\n",
      "Requirement already satisfied: distributed>=2.3.2; extra == \"dask\" in e:\\anaconda\\lib\\site-packages (from modin[dask]) (2.13.0)\n",
      "Requirement already satisfied: dask>=2.1.0; extra == \"dask\" in e:\\anaconda\\lib\\site-packages (from modin[dask]) (2.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin[dask]) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin[dask]) (2018.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda\\lib\\site-packages (from pandas==1.0.1->modin[dask]) (1.18.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\anaconda\\lib\\site-packages (from packaging->modin[dask]) (2.2.0)\n",
      "Requirement already satisfied: six in e:\\anaconda\\lib\\site-packages (from packaging->modin[dask]) (1.11.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (0.5.5)\n",
      "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (5.1)\n",
      "Requirement already satisfied: zict>=0.1.3 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (0.1.3)\n",
      "Requirement already satisfied: psutil>=5.0 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (5.4.7)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (40.2.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (1.6.0)\n",
      "Requirement already satisfied: pyyaml in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (3.13)\n",
      "Requirement already satisfied: click>=6.6 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (6.7)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (1.0.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (0.9.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in e:\\anaconda\\lib\\site-packages (from distributed>=2.3.2; extra == \"dask\"->modin[dask]) (2.0.5)\n",
      "Requirement already satisfied: heapdict in e:\\anaconda\\lib\\site-packages (from zict>=0.1.3->distributed>=2.3.2; extra == \"dask\"->modin[dask]) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# using these code to install modin and computation engine ray and dask\n",
    "! pip install numpy --upgrade \n",
    "! pip install modin\n",
    "! pip install modin[dask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in e:\\anaconda\\lib\\site-packages (2.13.0)\n",
      "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
      "  Downloading fsspec-0.6.3-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: pandas>=0.23.0; extra == \"dataframe\" in e:\\anaconda\\lib\\site-packages (from dask[dataframe]) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in e:\\anaconda\\lib\\site-packages (from dask[dataframe]) (1.18.2)\n",
      "Collecting partd>=0.3.10; extra == \"dataframe\"\n",
      "  Downloading partd-1.1.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: toolz>=0.8.2; extra == \"dataframe\" in e:\\anaconda\\lib\\site-packages (from dask[dataframe]) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in e:\\anaconda\\lib\\site-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in e:\\anaconda\\lib\\site-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2018.5)\n",
      "Requirement already satisfied: locket in e:\\anaconda\\lib\\site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[dataframe]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (1.11.0)\n",
      "Installing collected packages: fsspec, partd\n",
      "  Attempting uninstall: partd\n",
      "    Found existing installation: partd 0.3.8\n",
      "    Uninstalling partd-0.3.8:\n",
      "      Successfully uninstalled partd-0.3.8\n",
      "Successfully installed fsspec-0.6.3 partd-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Using Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as pd_modin\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use `Pandas on Ray` just as we use `Pandas`. I am testing  with a 143MB [decompressed file](http://www.kaggle.com/camnugent/sandp500/data on my laptop with 4 physical cores and 8GB Memor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_modin = pd_modin.read_csv(\"all_stocks_5yr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open   high    low  close    volume Name\n",
      "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
      "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
      "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
      "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
      "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL\n"
     ]
    }
   ],
   "source": [
    "print(df_modin.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_modin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'Name'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modin.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by doing some simple query like how many days ended with positive gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     2013-02-13\n",
      "5     2013-02-15\n",
      "11    2013-02-26\n",
      "12    2013-02-27\n",
      "14    2013-03-01\n",
      "15    2013-03-04\n",
      "16    2013-03-05\n",
      "17    2013-03-06\n",
      "18    2013-03-07\n",
      "20    2013-03-11\n",
      "Name: date, dtype: object\n",
      "\n",
      "Number of positive days: dd.Scalar<size-ag..., dtype=int32>\n",
      "Wall time: 449 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_df = df_modin.query(\"close > open\")\n",
    "print(pos_df['date'].head(n=10))\n",
    "print(\"\\nNumber of positive days:\", pos_df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_by_Time = df_modin.groupby(by=\"date\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high  low  close  volume  Name\n",
       "date                                            \n",
       "2013-02-08   476   476  476    476     476   476\n",
       "2013-02-11   476   476  476    476     476   476\n",
       "2013-02-12   476   476  476    476     476   476\n",
       "2013-02-13   476   476  476    476     476   476\n",
       "2013-02-14   476   476  476    476     476   476"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_by_Time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Modin` has integrated `pandas` API that is commonly used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I am gonna compare `Modin`with a dask engine and raw `pandas`. Considering that `Modin` is now working on full `Pandas` feature API, here I present some commonly used feature. The dataset I am using can be found [here](https://www.kaggle.com/wendykan/lending-club-loan-data)(1.1GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as old_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we ill compare how much time it consumes to load a CSV file between using a traditional `pandas` and `Modin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin with dask engine: \n",
      "Wall time: 285 ms\n",
      "\n",
      " Pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "# Modin with dask engine\n",
    "print(\"Modin with dask engine: \")\n",
    "%time pandas_on_modin = pd_modin.read_csv(\"loan.csv\")\n",
    "\n",
    "# raw Pandas\n",
    "print(\"\\n Pandas\")\n",
    "%time pandas_raw = pd.read_csv(\"loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0 NaN        NaN       2500         2500           2500.0   36 months   \n",
      "1 NaN        NaN      30000        30000          30000.0   60 months   \n",
      "2 NaN        NaN       5000         5000           5000.0   36 months   \n",
      "3 NaN        NaN       4000         4000           4000.0   36 months   \n",
      "4 NaN        NaN      30000        30000          30000.0   60 months   \n",
      "\n",
      "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
      "0     13.56        84.92     C        C1  ...                            NaN   \n",
      "1     18.94       777.23     D        D2  ...                            NaN   \n",
      "2     17.97       180.69     D        D1  ...                            NaN   \n",
      "3     18.94       146.51     D        D2  ...                            NaN   \n",
      "4     16.14       731.78     C        C4  ...                            NaN   \n",
      "\n",
      "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
      "0                          NaN                Cash                     N   \n",
      "1                          NaN                Cash                     N   \n",
      "2                          NaN                Cash                     N   \n",
      "3                          NaN                Cash                     N   \n",
      "4                          NaN                Cash                     N   \n",
      "\n",
      "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
      "0                       NaN               NaN             NaN   \n",
      "1                       NaN               NaN             NaN   \n",
      "2                       NaN               NaN             NaN   \n",
      "3                       NaN               NaN             NaN   \n",
      "4                       NaN               NaN             NaN   \n",
      "\n",
      "  settlement_amount  settlement_percentage settlement_term  \n",
      "0               NaN                    NaN             NaN  \n",
      "1               NaN                    NaN             NaN  \n",
      "2               NaN                    NaN             NaN  \n",
      "3               NaN                    NaN             NaN  \n",
      "4               NaN                    NaN             NaN  \n",
      "\n",
      "[5 rows x 145 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pandas_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see `Modin` with dask engine is about 266 times faster than raw `pandas`. This is quite impressive. As I have demonstrated before, `Modin` employs data partitioners to partition data along both rows and columns, and therefore it can use multiple CPU cores to complete the task. To prove this argument, we can collect all the data and see how long this may take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin with dask engine: \n",
      "Wall time: 2.99 ms\n",
      "\n",
      " Pandas\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# Modin with dask engine\n",
    "print(\"Modin with dask engine: \")\n",
    "%time entire_df_mod = pandas_on_modin[:]\n",
    "\n",
    "# raw Pandas\n",
    "print(\"\\n Pandas\")\n",
    "%time entire_df_raw = pandas_raw[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that `Modin` with dask engine is way slower than raw `pandas`. By using the operator `[:]`, we are collecting all the data. Due to parallization, with `Modin` with dask engine, all the threads are running in-parallel to read the file and serialize the data in different place. When we have to collect the data, there is only one thread deserializing the data which will make it the bottleneck. Next, we can check it out indexing the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin with dask engine: \n",
      "Wall time: 0 ns\n",
      "\n",
      " Pandas\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2260668, step=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modin with dask engine\n",
    "print(\"Modin with dask engine: \")\n",
    "%time pandas_on_modin.index\n",
    "\n",
    "# raw Pandas\n",
    "print(\"\\n Pandas\")\n",
    "%time pandas_raw.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how `Pandas` and `Modin` performs in query processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin with dask engine: \n",
      "21.1 ms ± 1.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      " Pandas\n",
      "The slowest run took 6.05 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1.51 s ± 1.27 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Modin with dask engine\n",
    "print(\"Modin with dask engine: \")\n",
    "%timeit q0 =  pandas_on_modin.query(\"int_rate > 15\")\n",
    "\n",
    "# raw Pandas\n",
    "print(\"\\n Pandas\")\n",
    "%timeit q1 = pandas_raw.query(\"int_rate > 15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can in this `timeit` call, `Modin` is about 5 times faster than raw `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reference\n",
    "* [RAY vs DASK](https://gist.github.com/devin-petersohn/f424d9fb5579a96507c709a36d487f24#file-pandas_on_ray_blog_post_0-ipynb)\n",
    "* [Modin Tutorial](https://modin.readthedocs.io/en/latest/using_modin.html#using-modin-on-a-single-node)\n",
    "* [Modin](https://www.zhihu.com/question/24590883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.2 Using Modin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
