{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "# Spotlight: Deeper investigation of some neat aspects of pandas\n",
    "\n",
    "### By: Tianyu Huang\n",
    "\n",
    "### Due: April 9, 2020\n",
    "\n",
    "## Introduction\n",
    "In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license. The name is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals.\n",
    "\n",
    "Pandas is mainly used for machine learning in form of dataframes. Pandas allow importing data of various file formats such as csv, excel etc. Pandas allows various data manipulation operations such as groupby, join, merge, melt, concatenation as well as data cleaning features such as filling, replacing or imputing null values.\n",
    "\n",
    "This article mainly introduces some advanced functions and usages that are commonly used, including groupby(), apply(), pivot_table(), time series operations and string operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: groupby()\n",
    "\n",
    "* Regardless of whether the grouping key is an array, list, dictionary, series, function, as long as it is the same as the axis length of the variable to be grouped, it can be passed into groupby() for grouping.\n",
    "* The default axis = 0 is grouped by row, and you can specify axis = 1 to group columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value\n",
      "0   A      0\n",
      "1   B      5\n",
      "2   C     10\n",
      "3   A      5\n",
      "4   B     10\n",
      "5   C     15\n",
      "6   A     10\n",
      "7   B     15\n",
      "8   C     20\n",
      "     value\n",
      "key       \n",
      "A       15\n",
      "B       30\n",
      "C       45\n"
     ]
    }
   ],
   "source": [
    "# form a dataframe\n",
    "data = pd.DataFrame({'key':['A','B','C','A','B','C','A','B','C'],\n",
    "                     'value':[0,5,10,5,10,15,10,15,20]})\n",
    "print(data)\n",
    "print(data.groupby('key').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is just a sum operation, of course, you can also use many statistical methods: size(), count(), max(), min(), mean(), etc.\n",
    "\n",
    "The point to note is the difference between the size() method and the count() method. Size() directly counts the number of occurrences of the key, so there will be no value column in the result, and the size() method will count missing values, and count() will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value\n",
      "0   A    0.0\n",
      "1   B    5.0\n",
      "2   C   10.0\n",
      "3   A    5.0\n",
      "4   B    NaN\n",
      "key\n",
      "A    2\n",
      "B    2\n",
      "C    1\n",
      "dtype: int64\n",
      "     value\n",
      "key       \n",
      "A        2\n",
      "B        1\n",
      "C        1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data2 = pd.DataFrame({'key':['A','B','C','A','B'],'value':[0,5,10,5,np.nan]})\n",
    "print(data2)\n",
    "print(data2.groupby('key').size())\n",
    "print(data2.groupby('key').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can take out the group alone to do some operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001DA0C3BE948>\n",
      "---------------\n",
      "A \n",
      "   key  value\n",
      "0   A      0\n",
      "3   A      5\n",
      "6   A     10\n",
      "-------------\n",
      "value    5.0\n",
      "dtype: float64\n",
      "---------------\n",
      "B \n",
      "   key  value\n",
      "1   B      5\n",
      "4   B     10\n",
      "7   B     15\n",
      "-------------\n",
      "value    10.0\n",
      "dtype: float64\n",
      "---------------\n",
      "C \n",
      "   key  value\n",
      "2   C     10\n",
      "5   C     15\n",
      "8   C     20\n",
      "-------------\n",
      "value    15.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First grouped, but no aggregation operation, the result is a groupby object\n",
    "groups = data.groupby('key')\n",
    "print(groups)\n",
    "\n",
    "# Can follow the dictionary format to traverse\n",
    "for index,group in groups:\n",
    "    print('---------------')\n",
    "    print(index,'\\n',group)\n",
    "    print('-------------')\n",
    "    \n",
    "    # mean()\n",
    "    print(group.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_group()\n",
    "Use this method to select the desired group, key value index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value\n",
      "0   A      0\n",
      "1   B      5\n",
      "2   A     10\n",
      "3   B      5\n",
      "  key  value\n",
      "0   A      0\n",
      "2   A     10\n",
      "  key  value\n",
      "1   B      5\n",
      "3   B      5\n"
     ]
    }
   ],
   "source": [
    "data3 = pd.DataFrame({'key':['A','B','A','B'],'value':[0,5,10,5]})\n",
    "print(data3)\n",
    "print(data3.groupby('key').get_group('A'))\n",
    "print(data3.groupby('key').get_group('B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple index\n",
    "In many cases, we will encounter the problem of multiple indexes, how to use groupby better, you can formulate level parameters\n",
    "\n",
    "level = 0 means only the first index is used, level = 1 means only the second index is used, and so on, and the index name can also be specified directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first  second\n",
      "bar    one       0.139614\n",
      "       two       0.526843\n",
      "baz    one      -0.108668\n",
      "       two       0.796672\n",
      "foo    one      -2.213745\n",
      "       two       1.569220\n",
      "qux    one       0.631751\n",
      "       two       0.489118\n",
      "dtype: float64\n",
      "------------------\n",
      "first\n",
      "bar    0.666457\n",
      "baz    0.688004\n",
      "foo   -0.644525\n",
      "qux    1.120869\n",
      "dtype: float64\n",
      "------------------\n",
      "second\n",
      "one   -1.551048\n",
      "two    3.381854\n",
      "dtype: float64\n",
      "------------------\n",
      "first\n",
      "bar    0.666457\n",
      "baz    0.688004\n",
      "foo   -0.644525\n",
      "qux    1.120869\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use pandas method to generate a series of secondary index structure\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "index = pd.MultiIndex.from_arrays(arrays,names = ['first','second'])\n",
    "s = pd.Series(np.random.randn(8),index = index)\n",
    "print(s)\n",
    "print('------------------')\n",
    "print(s.groupby(level =0).sum())\n",
    "print('------------------')\n",
    "print(s.groupby(level =1).sum())\n",
    "print('------------------')\n",
    "print(s.groupby(level ='first').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2: Custom function\n",
    "In pandas, you can use apply, map, agg to perform custom function operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value\n",
      "0   A      0\n",
      "1   B      5\n",
      "2   A     10\n",
      "3   B      5\n",
      "----------------\n",
      "0     1\n",
      "1     6\n",
      "2    11\n",
      "3     6\n",
      "Name: value, dtype: int64\n",
      "0     1\n",
      "1     6\n",
      "2    11\n",
      "3     6\n",
      "Name: value, dtype: int64\n",
      "0     1\n",
      "1     6\n",
      "2    11\n",
      "3     6\n",
      "Name: value, dtype: int64\n",
      "----------------\n",
      "   value\n",
      "0      1\n",
      "1      6\n",
      "2     11\n",
      "3      6\n",
      "     value\n",
      "key       \n",
      "A        5\n",
      "B        5\n"
     ]
    }
   ],
   "source": [
    "# Define a function, the role is to increase the value by 1\n",
    "data3 = pd.DataFrame({'key':['A','B','A','B'],'value':[0,5,10,5]})\n",
    "print(data3)\n",
    "\n",
    "def add_1(value):\n",
    "    return value + 1\n",
    "\n",
    "print(\"----------------\")\n",
    "print(data3['value'].apply(add_1))\n",
    "print(data3['value'].map(add_1))\n",
    "print(data3['value'].agg(add_1))\n",
    "\n",
    "print('----------------')\n",
    "print(data3.groupby('key').apply(add_1))\n",
    "print(data3.groupby('key').agg({'value':np.mean}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Pivot table\n",
    "Pivot Table is an interactive table that can perform certain calculations, such as summing and counting. The calculations and data are related to the arrangement in the pivot table.\n",
    "\n",
    "They are called pivot tables because they can dynamically change their layout to analyze data in different ways, and they can also rearrange row numbers, column labels, and page fields. Every time the layout is changed, the PivotTable will immediately recalculate the data according to the new layout. In addition, if the original data changes, you can update the PivotTable.\n",
    "Pandas uses pivot_table() method to generate pivot table.\n",
    "\n",
    "A simple example of summation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B      C  D  E\n",
      "0  foo  one  small  1  2\n",
      "1  foo  one  large  2  4\n",
      "2  foo  one  large  2  5\n",
      "3  foo  two  small  3  5\n",
      "4  foo  two  small  3  6\n",
      "5  bar  one  large  4  6\n",
      "6  bar  one  small  5  8\n",
      "7  bar  two  small  6  9\n",
      "8  bar  two  large  7  9\n",
      "--------------------------\n",
      "C        large  small\n",
      "A   B                \n",
      "bar one    4.0    5.0\n",
      "    two    7.0    6.0\n",
      "foo one    4.0    1.0\n",
      "    two    NaN    6.0\n"
     ]
    }
   ],
   "source": [
    "# form a dataframe\n",
    "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
    "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                         \"one\", \"one\", \"two\", \"two\"],\n",
    "                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
    "                         \"small\", \"large\", \"small\", \"small\",\n",
    "                          \"large\"],\n",
    "                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "print(df)\n",
    "print('--------------------------')\n",
    "# Take A and B as row indexes and C as column indexes to sum D\n",
    "print(pd.pivot_table(df, values='D', index=['A', 'B'],\n",
    "                  columns=['C'], aggfunc=np.sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing value as 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C        large  small\n",
      "A   B                \n",
      "bar one      4      5\n",
      "    two      7      6\n",
      "foo one      4      1\n",
      "    two      0      6\n"
     ]
    }
   ],
   "source": [
    "print(pd.pivot_table(df, values='D', index=['A', 'B'],\n",
    "                     columns=['C'], aggfunc=np.sum, fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take multiple aggregations in multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  D    E               \n",
      "               mean  max      mean  min\n",
      "A   C                                  \n",
      "bar large  5.500000  9.0  7.500000  6.0\n",
      "    small  5.500000  9.0  8.500000  8.0\n",
      "foo large  2.000000  5.0  4.500000  4.0\n",
      "    small  2.333333  6.0  4.333333  2.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
    "                   aggfunc={'D': np.mean,\n",
    "                            'E': [min, max, np.mean]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Time series operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time stamps and time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-19 00:00:00\n",
      "0   2019-08-19 00:00:00\n",
      "1   2019-08-19 12:00:00\n",
      "2   2019-08-20 00:00:00\n",
      "3   2019-08-20 12:00:00\n",
      "4   2019-08-21 00:00:00\n",
      "5   2019-08-21 12:00:00\n",
      "6   2019-08-22 00:00:00\n",
      "7   2019-08-22 12:00:00\n",
      "8   2019-08-23 00:00:00\n",
      "9   2019-08-23 12:00:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "ts = pd.Timestamp('2019-8-19')\n",
    "print(ts)\n",
    "print(pd.Series(pd.date_range(start='2019-8-19',periods = 10,freq = '12H')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time index and indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      L06_347  LS06_347  LS06_348\n",
      "Time                                             \n",
      "2012-01-01 09:00:00  0.330750  0.293583  0.029750\n",
      "2012-01-01 12:00:00  0.295000  0.285167  0.031750\n",
      "2012-01-01 15:00:00  0.301417  0.287750  0.031417\n",
      "2012-01-01 18:00:00  0.322083  0.304167  0.038083\n",
      "                      L06_347  LS06_347  LS06_348\n",
      "Time                                             \n",
      "2013-01-01 00:00:00  1.688333  1.688333  0.207333\n",
      "2013-01-01 03:00:00  2.693333  2.693333  0.201500\n",
      "2013-01-01 06:00:00  2.220833  2.220833  0.166917\n",
      "2013-01-01 09:00:00  2.055000  2.055000  0.175667\n",
      "2013-01-01 12:00:00  1.710000  1.710000  0.129583\n",
      "2013-01-01 15:00:00  1.420000  1.420000  0.096333\n",
      "2013-01-01 18:00:00  1.178583  1.178583  0.083083\n",
      "2013-01-01 21:00:00  0.898250  0.898250  0.077167\n",
      "2013-01-02 00:00:00  0.860000  0.860000  0.075000\n",
      "                      L06_347  LS06_347  LS06_348\n",
      "Time                                             \n",
      "2012-01-01 00:00:00  0.307167  0.273917  0.028000\n",
      "2012-01-01 03:00:00  0.302917  0.270833  0.030583\n",
      "2012-01-01 06:00:00  0.331500  0.284750  0.030917\n",
      "2012-01-01 09:00:00  0.330750  0.293583  0.029750\n",
      "2012-01-01 12:00:00  0.295000  0.285167  0.031750\n",
      "2012-01-01 15:00:00  0.301417  0.287750  0.031417\n",
      "2012-01-01 18:00:00  0.322083  0.304167  0.038083\n",
      "2012-01-01 21:00:00  0.355417  0.346500  0.080917\n",
      "2012-01-02 00:00:00  1.069333  0.970000  0.071917\n",
      "2012-01-02 03:00:00  0.886667  0.817417  0.070833\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./flowdata.csv',index_col = 'Time',parse_dates = True)\n",
    "# Time slice\n",
    "print(data[('2012-01-01 09:00'):('2012-01-01 19:00')])\n",
    "# year index\n",
    "print(data['2013'])\n",
    "# Index data from January to February 2012\n",
    "print(data['2012-01':'2012-02'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             L06_347  LS06_347  LS06_348\n",
      "Time                                    \n",
      "2009-01-01  0.125010  0.092281  0.016635\n",
      "2009-01-02  0.124146  0.095781  0.016406\n",
      "2009-01-03  0.113562  0.085542  0.016094\n",
      "2009-01-04  0.140198  0.102708  0.017323\n",
      "2009-01-05  0.128812  0.104490  0.018167\n",
      "               L06_347     LS06_347   LS06_348\n",
      "Time                                          \n",
      "2009-12-31  640.507333   639.476750  71.634750\n",
      "2010-12-31  994.468583  1029.896542  75.620100\n",
      "2011-12-31  704.901583   692.756488  49.946350\n",
      "2012-12-31  669.086250   659.646667  64.412572\n",
      "2013-12-31   14.724333    14.724333   1.212583\n"
     ]
    }
   ],
   "source": [
    "# Average by day\n",
    "print(data.resample('D').mean().head())\n",
    "# Sum by year\n",
    "print(data.resample('Y').sum().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: String manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  1  0  0\n",
      "1  1  1  0\n",
      "2  1  0  1\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a','a|b','a|c'])\n",
    "print(s.str.get_dummies(sep = '|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [a, b, C]\n",
      "1    [c, d, e]\n",
      "2    [f, g, h]\n",
      "dtype: object\n",
      "   0  1  2\n",
      "0  a  b  C\n",
      "1  c  d  e\n",
      "2  f  g  h\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a_b_C','c_d_e','f_g_h'])\n",
    "print(s.str.split('_'))\n",
    "print(s.str.split('_',expand = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A_a       B_b\n",
      "0 -0.960445  0.624197\n",
      "1  0.791194 -1.353642\n",
      "2 -0.478425  0.272510\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3,2),columns = ['A a','B b'],index = range(3))\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
