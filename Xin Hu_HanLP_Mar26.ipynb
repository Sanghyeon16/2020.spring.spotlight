{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "# Spotlight By Xin Hu - HanLP  \n",
    "\n",
    "## Introduction\n",
    "HanLP is a multilingual NLP library developed by Han He. This library is\n",
    "built on Tensorflow 2.0 and mainly use RNN network, for advancing state-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to be efficient, user friendly and extendable. It comes with pretrained models for various human languages including English, Chinese and many others.\n",
    "\n",
    "HanLP provides different features to help in NLP, these features include:\n",
    "\n",
    "- [Tokenization](#Tokenization)\n",
    "\n",
    "- [Part-of-Speech Tagging](#Part)\n",
    "\n",
    "- [Named Entity Recognition](#name)\n",
    "\n",
    "- [Syntactic Dependency Parsing](#syn)\n",
    "\n",
    "- [Semantic Dependency Parsing](#sem)\n",
    "\n",
    "HanLP also provides a pipeline to combine all of these features, this spotlight will try to explore these features and introduce how to train a model.\n",
    "\n",
    "## Installation\n",
    "HanLP is an easy install library, just run the command as follows:\n",
    "\n",
    "```python\n",
    "pip install HanLP\n",
    "```\n",
    "\n",
    "HanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.\n",
    "\n",
    "## Get Start\n",
    "<a id = 'Tokenization'></a>\n",
    "### Tokenization\n",
    "For a comman user, the basic workflow always start with loading a pretrained model and apply it on his work. HanLP provides pretrained model, then we can use it directly. Take Chinese tokenizer as an example, we need to call **CTB6_CONVSEG** to load the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Range in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LookupTableImportV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MutexV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "#load model from identifier\n",
    "Ctokenizer = hanlp.load('CTB6_CONVSEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HanLP will automatically resolve the identifier CTB6_CONVSEG to an URL, then download it and unzip it. \n",
    "\n",
    "Once the model is loaded, we can then tokenize one or even multiple sentences through calling the tokenizer as a\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "['周瑜', '打', '黄盖']\n"
     ]
    }
   ],
   "source": [
    "#try the loaded model\n",
    "print(Ctokenizer(\"周瑜打黄盖\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[['我', '想', '过', '过', '过儿', '过', '过', '的', '生活'], ['香港', '繁體', '也', '可以', '進行', '分割']]\n"
     ]
    }
   ],
   "source": [
    "print(Ctokenizer([\"我想过过过儿过过的生活\",\"香港繁體也可以進行分割\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "From results above, it could recognize simple Chinese and traditional Chinese, then tokenize them. This will help us in different Chinese articles from China(mainland), Hong Kong(China) and Taiwan(China).\n",
    "\n",
    "**If we want to parse English sentence, then we need to change rules of tokenizer to English rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZhouYu', 'hits', 'HuangGai']\n"
     ]
    }
   ],
   "source": [
    "#change sentence anylisis rules to English rules\n",
    "Etokenizer = hanlp.utils.rules.tokenize_english\n",
    "print(Etokenizer(\"ZhouYu hits HuangGai\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to check how many models HanLP provides, then we can run the code as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SIGHAN2005_PKU_CONVSEG': 'https://file.hankcs.com/hanlp/cws/sighan2005-pku-convseg_20200110_153722.zip', 'SIGHAN2005_MSR_CONVSEG': 'https://file.hankcs.com/hanlp/cws/convseg-msr-nocrf-noembed_20200110_153524.zip', 'CTB6_CONVSEG': 'https://file.hankcs.com/hanlp/cws/ctb6_convseg_nowe_nocrf_20200110_004046.zip', 'PKU_NAME_MERGED_SIX_MONTHS_CONVSEG': 'https://file.hankcs.com/hanlp/cws/pku98_6m_conv_ngram_20200110_134736.zip', 'CTB5_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb5_20191229_025833.zip', 'CTB7_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb7_20200109_022431.zip', 'PTB_BIAFFINE_DEP_EN': 'https://file.hankcs.com/hanlp/dep/ptb_dep_biaffine_20200101_174624.zip', 'SEMEVAL16_NEWS_BIAFFINE_ZH': 'https://file.hankcs.com/hanlp/sdp/semeval16-news-biaffine_20191231_235407.zip', 'SEMEVAL16_TEXT_BIAFFINE_ZH': 'https://file.hankcs.com/hanlp/sdp/semeval16-text-biaffine_20200101_002257.zip', 'SEMEVAL15_PAS_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_pas_20200103_152405.zip', 'SEMEVAL15_PSD_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_psd_20200106_123009.zip', 'SEMEVAL15_DM_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_dm_20200106_122808.zip', 'GLOVE_6B_ROOT': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip', 'GLOVE_6B_50D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.50d.txt', 'GLOVE_6B_100D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.100d.txt', 'GLOVE_6B_200D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.200d.txt', 'GLOVE_6B_300D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.300d.txt', 'GLOVE_840B_300D': 'http://nlp.stanford.edu/data/glove.840B.300d.zip', 'CTB5_POS_RNN': 'https://file.hankcs.com/hanlp/pos/ctb5_pos_rnn_20200113_235925.zip', 'CTB5_POS_RNN_FASTTEXT_ZH': 'https://file.hankcs.com/hanlp/pos/ctb5_pos_rnn_fasttext_20191230_202639.zip', 'PTB_POS_RNN_FASTTEXT_EN': 'https://file.hankcs.com/hanlp/pos/ptb_pos_rnn_fasttext_20200103_145337.zip', 'FLAIR_LM_FW_WMT11_EN': 'https://file.hankcs.com/hanlp/lm/flair_lm_wmt11_en_20200211_091932.zip#flair_lm_fw_wmt11_en', 'FLAIR_LM_BW_WMT11_EN': 'https://file.hankcs.com/hanlp/lm/flair_lm_wmt11_en_20200211_091932.zip#flair_lm_bw_wmt11_en', 'CONVSEG_W2V_NEWS_TENSITE': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip', 'CONVSEG_W2V_NEWS_TENSITE_WORD_PKU': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.pku.words.w2v50', 'CONVSEG_W2V_NEWS_TENSITE_WORD_MSR': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.msr.words.w2v50', 'CONVSEG_W2V_NEWS_TENSITE_CHAR': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.w2v200', 'SEMEVAL16_EMBEDDINGS_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip', 'SEMEVAL16_EMBEDDINGS_300_NEWS_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip#news.fasttext.300.txt', 'SEMEVAL16_EMBEDDINGS_300_TEXT_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip#text.fasttext.300.txt', 'CTB5_FASTTEXT_300_CN': 'https://file.hankcs.com/hanlp/embeddings/ctb.fasttext.300.txt.zip', 'TENCENT_AI_LAB_EMBEDDING': 'https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz#Tencent_AILab_ChineseEmbedding.txt', 'RADICAL_CHAR_EMBEDDING_100': 'https://file.hankcs.com/hanlp/embeddings/radical_char_vec_20191229_013849.zip#character.vec.txt', 'MSRA_NER_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/ner_bert_base_msra_20200104_185735.zip', 'MSRA_NER_ALBERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/ner_albert_base_zh_msra_20200111_202919.zip', 'CONLL03_NER_BERT_BASE_UNCASED_EN': 'https://file.hankcs.com/hanlp/ner/ner_conll03_bert_base_uncased_en_20200104_194352.zip', 'CHNSENTICORP_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/classification/chnsenticorp_bert_base_20200104_164655.zip', 'SST2_BERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/sst2_bert_base_uncased_en_20200210_090240.zip', 'SST2_ALBERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/sst2_albert_base_20200122_205915.zip', 'EMPATHETIC_DIALOGUES_SITUATION_ALBERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/empathetic_dialogues_situation_albert_base_20200122_212250.zip', 'EMPATHETIC_DIALOGUES_SITUATION_ALBERT_LARGE_EN': 'https://file.hankcs.com/hanlp/classification/empathetic_dialogues_situation_albert_large_20200123_142724.zip'}\n"
     ]
    }
   ],
   "source": [
    "print(hanlp.pretrained.ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "From the results above, we can find that HanLP provides several different kinds of pretrained model, including: \n",
    "**classifier**,**cws**,**dep**,**glove**,**ner**,**pos**,**rnnlm**,**sdp** and **word2vec**.When we are going \n",
    "on a detailed project, these can help us quickly find what we really need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part'></a>\n",
    "### Part-of-Speech Tagging\n",
    "Taggers take list of tokens as input, then output tag of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "['我', '的', '希望', '是', '希望', '和平', '.']\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "['PN', 'DEG', 'NN', 'VC', 'VV', 'NN', 'PU']\n"
     ]
    }
   ],
   "source": [
    "tokens = Ctokenizer(\"我的希望是希望和平.\")\n",
    "print(tokens)\n",
    "taggers = hanlp.load(hanlp.pretrained.pos.CTB5_POS_RNN_FASTTEXT_ZH)\n",
    "print(taggers(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "\"希望\" in English is \"hope\", The first \"希望\" is \"my dream\", it is a noun, while second is verb, it means \"want\". So HanLP can recognize these words meaning exactly and translate them in tag.\n",
    "If we want to tag English words, we can load hanlp.pretrained.pos.PTB_POS_RNN_FASTTEXT_EN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'name'></a>\n",
    "### Named Entity Recognition\n",
    "NER in HanLP provides different entity in different language. For example, in English, \"Obama\" will be recognized as \"PER\", while \"奥巴马\" in Chinese will be \"NR\". NER also takes list of tokens as input, output a tuple for each token. Each tuple has four elements - (entity, type, begin, end). These elements give us a hand when we need pos of each word. I will take Chinese as example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Done loading 197 BERT weights from: C:\\Users\\Administrator\\AppData\\Roaming\\hanlp\\thirdparty\\storage.googleapis.com\\bert_models\\2018_11_03\\chinese_L-12_H-768_A-12\\bert_model.ckpt into <bert.model.BertModelLayer object at 0x000001CF8773BB70> (prefix:bert_8). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_function_152737 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "[('张宇', 'NR', 0, 2), ('长城', 'NS', 5, 7), ('河南', 'NS', 10, 12), ('海淀宾馆', 'NT', 18, 22)]\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)\n",
    "print(recognizer(list(\"张宇爬上了长城， 喝河南胡辣汤， 在海淀宾馆睡了一觉\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "This MSRA_NER_BERT_BASE_ZH is the state-of-the-art NER model based on BERT. While it can recognize some entities, there are still some ignored. NER in HanLP still needs improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'syn'></a>\n",
    "### Syntactic Dependency Parsing\n",
    "\n",
    "Parsing lies in the core of web search and recommendation. Without parsing, it will be hard for us to find the relevance between query and document. In the homwork before, we use NLTK, stemming to parse documents. But using HanLP, it takes no more than two lines of code. Take Chinese articles as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "['我', '的', '希望', '是', '希望', '和平', '.'] ['PN', 'DEG', 'NN', 'VC', 'VV', 'NN', 'PU']\n",
      "[('我', 'PN'), ('的', 'DEG'), ('希望', 'NN'), ('是', 'VC'), ('希望', 'VV'), ('和平', 'NN'), ('.', 'PU')]\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "1\t我\t_\tPN\t_\t_\t3\tassmod\t_\t_\n",
      "2\t的\t_\tDEG\t_\t_\t1\tassm\t_\t_\n",
      "3\t希望\t_\tNN\t_\t_\t4\ttop\t_\t_\n",
      "4\t是\t_\tVC\t_\t_\t0\troot\t_\t_\n",
      "5\t希望\t_\tVV\t_\t_\t4\tccomp\t_\t_\n",
      "6\t和平\t_\tNN\t_\t_\t5\tdobj\t_\t_\n",
      "7\t.\t_\tPU\t_\t_\t4\tpunct\t_\t_\n"
     ]
    }
   ],
   "source": [
    "#use tag and tokens above as input\n",
    "tag = taggers(tokens)\n",
    "print(tokens,tag)\n",
    "parse_input = []\n",
    "for i in range(len(tokens)):\n",
    "    parse_input.append((tokens[i],tag[i]))\n",
    "print(parse_input)\n",
    "syntactic_parser = hanlp.load(hanlp.pretrained.dep.CTB7_BIAFFINE_DEP_ZH)\n",
    "print(syntactic_parser(parse_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactic dependency parsing in HanLP relies on the ICLR 2017 paper by Dozat(stanford), this paper got the highest score in graph based method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "Parsers take both tokens and part-of-speech tags as input. The output is a tree in CoNLL-X format[^conllx], which can be manipulated through the CoNLLSentence class.\n",
    "\n",
    "Through using the tokens and tags before, we can easily parse any sentence by several lines of code. HanLP saves us much time to parse.\n",
    "\n",
    "If want an English version, just load hanlp.pretrained.dep.PTB_BIAFFINE_DEP_EN, also applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sem'></a>\n",
    "### Semantic Dependency Parsing\n",
    "A graph is a generalized tree, which conveys more information about the semantic relations between tokens.\n",
    "\n",
    "HanLP implements the biaffine[^biaffine] model which delivers the SOTA performance.\n",
    "\n",
    "Take the same example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "1\t我\t_\tPN\t_\t_\t3\tPoss\t_\t_\n",
      "2\t的\t_\tDEG\t_\t_\t1\tmAux\t_\t_\n",
      "3\t希望\t_\tNN\t_\t_\t4\tExp\t_\t_\n",
      "4\t是\t_\tVC\t_\t_\t0\tRoot\t_\t_\n",
      "5\t希望\t_\tVV\t_\t_\t4\tdClas\t_\t_\n",
      "6\t和平\t_\tNN\t_\t_\t5\tCont\t_\t_\n",
      "7\t.\t_\tPU\t_\t_\t5\tmPunc\t_\t_\n"
     ]
    }
   ],
   "source": [
    "semantic_parser = hanlp.load(hanlp.pretrained.sdp.SEMEVAL16_NEWS_BIAFFINE_ZH)\n",
    "print(semantic_parser(parse_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic holds the same output structure as Syntactic, however, Semantic output is really a tree not a graph, which means each node would possibly have multiple head, as the following examples show: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "1\t柴火\t_\tNN\t_\t_\t3\tPoss\t_\t_\n",
      "1\t柴火\t_\tNN\t_\t_\t4\tPat\t_\t_\n",
      "2\t两\t_\tCD\t_\t_\t3\tQuan\t_\t_\n",
      "3\t头\t_\tNN\t_\t_\t4\tLoc\t_\t_\n",
      "4\t烧\t_\tVV\t_\t_\t0\tRoot\t_\t_\n"
     ]
    }
   ],
   "source": [
    "#take a special example\n",
    "Sinput = [('柴火', 'NN'), ('两', 'CD'), ('头', 'NN'), ('烧', 'VV')]\n",
    "print(semantic_parser(Sinput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "\"柴火\" has two heads(ID:3 and ID:4). Researchers can choose syntactic parsing or semantic parsing according to  what they really like. I think this is a good benefit of HanLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "Since parsers require part-of-speech tagging and tokenization, while taggers expects tokenization to be done beforehand, it could be nice if there is a pipeline for all the procedures. Luckily, HanLP provides such pipeline and save us expensive time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = hanlp.pipeline() \\\n",
    "    .append(hanlp.utils.rules.split_sentence, output_key='sentences') \\\n",
    "    .append(Ctokenizer, output_key='tokens') \\\n",
    "    .append(taggers, output_key='part_of_speech_tags') \\\n",
    "    .append(syntactic_parser, input_key=('tokens', 'part_of_speech_tags'), output_key='syntactic_dependencies') \\\n",
    "    .append(semantic_parser, input_key=('tokens', 'part_of_speech_tags'), output_key='semantic_dependencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first pipe is an old-school Python function split_sentence, which splits the input text into a list of sentences. Then the later DL components can utilize the batch processing seamlessly. This results in a pipeline with one input (text) pipe, multiple flow pipes and one output (parsed document).\n",
    "\n",
    "We can print pipeline to check its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None->LambdaComponent->sentences, sentences->NgramConvTokenizer->tokens, tokens->RNNPartOfSpeechTagger->part_of_speech_tags, ('tokens', 'part_of_speech_tags')->BiaffineDependencyParser->syntactic_dependencies, ('tokens', 'part_of_speech_tags')->BiaffineSemanticDependencyParser->semantic_dependencies]\n"
     ]
    }
   ],
   "source": [
    "#show the pipeline structure\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply pipeline on a real text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "{\n",
      "  \"sentences\": [\n",
      "    \"胡辣汤由多种天然中草药按比例配制的汤料再加入胡椒和辣椒又用骨头汤做底料的胡辣汤，其特点是汤味浓郁、汤色靓丽、汤汁粘稠，香辣可口，十分适合配合其它早点进餐。\",\n",
      "    \"目前，已经发展成为河南及陕西等周边省份都喜爱和知晓的小吃之一。\",\n",
      "    \"是中国河南的特色汤类食品，被大家所喜爱，常作为早餐，其特点是麻辣鲜香，营养开胃，适合搭配油条、包子、葱油饼、锅盔，千层饼等面点。\"\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    [\"胡辣汤\", \"由\", \"多\", \"种\", \"天然\", \"中草药\", \"按\", \"比例\", \"配制\", \"的\", \"汤料\", \"再\", \"加入\", \"胡椒\", \"和\", \"辣椒\", \"又\", \"用\", \"骨头\", \"汤\", \"做\", \"底料\", \"的\", \"胡辣汤\", \"，\", \"其\", \"特点\", \"是\", \"汤味\", \"浓郁\", \"、\", \"汤色\", \"靓丽\", \"、\", \"汤汁\", \"粘稠\", \"，\", \"香辣可口\", \"，\", \"十分\", \"适合\", \"配合\", \"其它\", \"早点\", \"进餐\", \"。\"],\n",
      "    [\"目前\", \"，\", \"已经\", \"发展\", \"成为\", \"河南\", \"及\", \"陕西\", \"等\", \"周边\", \"省份\", \"都\", \"喜爱\", \"和\", \"知晓\", \"的\", \"小吃\", \"之一\", \"。\"],\n",
      "    [\"是\", \"中国\", \"河南\", \"的\", \"特色\", \"汤类\", \"食品\", \"，\", \"被\", \"大家\", \"所\", \"喜爱\", \"，\", \"常\", \"作为\", \"早餐\", \"，\", \"其\", \"特点\", \"是\", \"麻辣\", \"鲜香\", \"，\", \"营养\", \"开胃\", \"，\", \"适合\", \"搭配\", \"油条\", \"、\", \"包子\", \"、\", \"葱油\", \"饼\", \"、\", \"锅盔\", \"，\", \"千\", \"层\", \"饼\", \"等\", \"面点\", \"。\"]\n",
      "  ],\n",
      "  \"part_of_speech_tags\": [\n",
      "    [\"NR\", \"P\", \"CD\", \"M\", \"JJ\", \"NN\", \"P\", \"NN\", \"NN\", \"DEC\", \"NN\", \"AD\", \"VV\", \"NN\", \"CC\", \"NN\", \"AD\", \"P\", \"NN\", \"NN\", \"VV\", \"JJ\", \"DEC\", \"NN\", \"PU\", \"PN\", \"NN\", \"VC\", \"NN\", \"VA\", \"PU\", \"NN\", \"VA\", \"PU\", \"NN\", \"NN\", \"PU\", \"VV\", \"PU\", \"AD\", \"VV\", \"VV\", \"DT\", \"NN\", \"VV\", \"PU\"],\n",
      "    [\"NT\", \"PU\", \"AD\", \"VV\", \"VV\", \"NR\", \"CC\", \"NR\", \"ETC\", \"NN\", \"NN\", \"AD\", \"VV\", \"CC\", \"NR\", \"DEG\", \"NN\", \"NN\", \"PU\"],\n",
      "    [\"VC\", \"NR\", \"NR\", \"DEG\", \"NN\", \"NN\", \"NN\", \"PU\", \"LB\", \"PN\", \"MSP\", \"VV\", \"PU\", \"AD\", \"VV\", \"NN\", \"PU\", \"PN\", \"NN\", \"VC\", \"JJ\", \"NN\", \"PU\", \"NN\", \"NN\", \"PU\", \"VV\", \"VV\", \"NN\", \"PU\", \"NN\", \"PU\", \"NN\", \"NN\", \"PU\", \"NN\", \"PU\", \"CD\", \"M\", \"NN\", \"ETC\", \"NN\", \"PU\"]\n",
      "  ],\n",
      "  \"syntactic_dependencies\": [\n",
      "    [{\"id\": 1, \"form\": \"胡辣汤\", \"cpos\": \"NR\", \"pos\": null, \"head\": 13, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"由\", \"cpos\": \"P\", \"pos\": null, \"head\": 13, \"deprel\": \"prep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"多\", \"cpos\": \"CD\", \"pos\": null, \"head\": 4, \"deprel\": \"nummod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"种\", \"cpos\": \"M\", \"pos\": null, \"head\": 6, \"deprel\": \"clf\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"天然\", \"cpos\": \"JJ\", \"pos\": null, \"head\": 6, \"deprel\": \"amod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"中草药\", \"cpos\": \"NN\", \"pos\": null, \"head\": 2, \"deprel\": \"pobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"按\", \"cpos\": \"P\", \"pos\": null, \"head\": 13, \"deprel\": \"prep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"比例\", \"cpos\": \"NN\", \"pos\": null, \"head\": 9, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"配制\", \"cpos\": \"NN\", \"pos\": null, \"head\": 11, \"deprel\": \"rcmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"的\", \"cpos\": \"DEC\", \"pos\": null, \"head\": 9, \"deprel\": \"cpm\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"汤料\", \"cpos\": \"NN\", \"pos\": null, \"head\": 2, \"deprel\": \"pobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"再\", \"cpos\": \"AD\", \"pos\": null, \"head\": 13, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"加入\", \"cpos\": \"VV\", \"pos\": null, \"head\": 0, \"deprel\": \"root\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"胡椒\", \"cpos\": \"NN\", \"pos\": null, \"head\": 16, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"和\", \"cpos\": \"CC\", \"pos\": null, \"head\": 16, \"deprel\": \"cc\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"辣椒\", \"cpos\": \"NN\", \"pos\": null, \"head\": 13, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"又\", \"cpos\": \"AD\", \"pos\": null, \"head\": 21, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"用\", \"cpos\": \"P\", \"pos\": null, \"head\": 21, \"deprel\": \"prep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"骨头\", \"cpos\": \"NN\", \"pos\": null, \"head\": 20, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 20, \"form\": \"汤\", \"cpos\": \"NN\", \"pos\": null, \"head\": 18, \"deprel\": \"pobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 21, \"form\": \"做\", \"cpos\": \"VV\", \"pos\": null, \"head\": 13, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 22, \"form\": \"底料\", \"cpos\": \"JJ\", \"pos\": null, \"head\": 24, \"deprel\": \"assmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 23, \"form\": \"的\", \"cpos\": \"DEC\", \"pos\": null, \"head\": 22, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 24, \"form\": \"胡辣汤\", \"cpos\": \"NN\", \"pos\": null, \"head\": 21, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 25, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 13, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 26, \"form\": \"其\", \"cpos\": \"PN\", \"pos\": null, \"head\": 27, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 27, \"form\": \"特点\", \"cpos\": \"NN\", \"pos\": null, \"head\": 28, \"deprel\": \"top\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 28, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": 13, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 29, \"form\": \"汤味\", \"cpos\": \"NN\", \"pos\": null, \"head\": 30, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 30, \"form\": \"浓郁\", \"cpos\": \"VA\", \"pos\": null, \"head\": 28, \"deprel\": \"ccomp\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 31, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": 30, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 32, \"form\": \"汤色\", \"cpos\": \"NN\", \"pos\": null, \"head\": 33, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 33, \"form\": \"靓丽\", \"cpos\": \"VA\", \"pos\": null, \"head\": 30, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 34, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": 30, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 35, \"form\": \"汤汁\", \"cpos\": \"NN\", \"pos\": null, \"head\": 36, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 36, \"form\": \"粘稠\", \"cpos\": \"NN\", \"pos\": null, \"head\": 30, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 37, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 30, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 38, \"form\": \"香辣可口\", \"cpos\": \"VV\", \"pos\": null, \"head\": 30, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 39, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 13, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 40, \"form\": \"十分\", \"cpos\": \"AD\", \"pos\": null, \"head\": 41, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 41, \"form\": \"适合\", \"cpos\": \"VV\", \"pos\": null, \"head\": 13, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 42, \"form\": \"配合\", \"cpos\": \"VV\", \"pos\": null, \"head\": 41, \"deprel\": \"ccomp\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 43, \"form\": \"其它\", \"cpos\": \"DT\", \"pos\": null, \"head\": 44, \"deprel\": \"det\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 44, \"form\": \"早点\", \"cpos\": \"NN\", \"pos\": null, \"head\": 42, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 45, \"form\": \"进餐\", \"cpos\": \"VV\", \"pos\": null, \"head\": 42, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 46, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": 13, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}],\n",
      "    [{\"id\": 1, \"form\": \"目前\", \"cpos\": \"NT\", \"pos\": null, \"head\": 5, \"deprel\": \"tmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 5, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"已经\", \"cpos\": \"AD\", \"pos\": null, \"head\": 4, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"发展\", \"cpos\": \"VV\", \"pos\": null, \"head\": 0, \"deprel\": \"root\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"成为\", \"cpos\": \"VV\", \"pos\": null, \"head\": 4, \"deprel\": \"rcomp\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"河南\", \"cpos\": \"NR\", \"pos\": null, \"head\": 8, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"及\", \"cpos\": \"CC\", \"pos\": null, \"head\": 8, \"deprel\": \"cc\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"陕西\", \"cpos\": \"NR\", \"pos\": null, \"head\": 11, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"等\", \"cpos\": \"ETC\", \"pos\": null, \"head\": 8, \"deprel\": \"etc\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"周边\", \"cpos\": \"NN\", \"pos\": null, \"head\": 11, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"省份\", \"cpos\": \"NN\", \"pos\": null, \"head\": 13, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"都\", \"cpos\": \"AD\", \"pos\": null, \"head\": 13, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"喜爱\", \"cpos\": \"VV\", \"pos\": null, \"head\": 18, \"deprel\": \"rcmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"和\", \"cpos\": \"CC\", \"pos\": null, \"head\": 13, \"deprel\": \"cc\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"知晓\", \"cpos\": \"NR\", \"pos\": null, \"head\": 13, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"的\", \"cpos\": \"DEG\", \"pos\": null, \"head\": 15, \"deprel\": \"assm\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"小吃\", \"cpos\": \"NN\", \"pos\": null, \"head\": 18, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"之一\", \"cpos\": \"NN\", \"pos\": null, \"head\": 4, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": 5, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}],\n",
      "    [{\"id\": 1, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": 0, \"deprel\": \"root\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"中国\", \"cpos\": \"NR\", \"pos\": null, \"head\": 3, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"河南\", \"cpos\": \"NR\", \"pos\": null, \"head\": 7, \"deprel\": \"assmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"的\", \"cpos\": \"DEG\", \"pos\": null, \"head\": 3, \"deprel\": \"assm\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"特色\", \"cpos\": \"NN\", \"pos\": null, \"head\": 7, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"汤类\", \"cpos\": \"NN\", \"pos\": null, \"head\": 7, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"食品\", \"cpos\": \"NN\", \"pos\": null, \"head\": 1, \"deprel\": \"attr\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 1, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"被\", \"cpos\": \"LB\", \"pos\": null, \"head\": 12, \"deprel\": \"pass\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"大家\", \"cpos\": \"PN\", \"pos\": null, \"head\": 12, \"deprel\": \"nsubj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"所\", \"cpos\": \"MSP\", \"pos\": null, \"head\": 12, \"deprel\": \"prtmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"喜爱\", \"cpos\": \"VV\", \"pos\": null, \"head\": 1, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 12, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"常\", \"cpos\": \"AD\", \"pos\": null, \"head\": 15, \"deprel\": \"advmod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"作为\", \"cpos\": \"VV\", \"pos\": null, \"head\": 12, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"早餐\", \"cpos\": \"NN\", \"pos\": null, \"head\": 15, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 1, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"其\", \"cpos\": \"PN\", \"pos\": null, \"head\": 19, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"特点\", \"cpos\": \"NN\", \"pos\": null, \"head\": 20, \"deprel\": \"top\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 20, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": 1, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 21, \"form\": \"麻辣\", \"cpos\": \"JJ\", \"pos\": null, \"head\": 22, \"deprel\": \"amod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 22, \"form\": \"鲜香\", \"cpos\": \"NN\", \"pos\": null, \"head\": 25, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 23, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 1, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 24, \"form\": \"营养\", \"cpos\": \"NN\", \"pos\": null, \"head\": 25, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 25, \"form\": \"开胃\", \"cpos\": \"NN\", \"pos\": null, \"head\": 20, \"deprel\": \"attr\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 26, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 20, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 27, \"form\": \"适合\", \"cpos\": \"VV\", \"pos\": null, \"head\": 1, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 28, \"form\": \"搭配\", \"cpos\": \"VV\", \"pos\": null, \"head\": 27, \"deprel\": \"ccomp\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 29, \"form\": \"油条\", \"cpos\": \"NN\", \"pos\": null, \"head\": 40, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 30, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": 40, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 31, \"form\": \"包子\", \"cpos\": \"NN\", \"pos\": null, \"head\": 40, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 32, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": 40, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 33, \"form\": \"葱油\", \"cpos\": \"NN\", \"pos\": null, \"head\": 34, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 34, \"form\": \"饼\", \"cpos\": \"NN\", \"pos\": null, \"head\": 40, \"deprel\": \"conj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 35, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": 40, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 36, \"form\": \"锅盔\", \"cpos\": \"NN\", \"pos\": null, \"head\": 40, \"deprel\": \"dep\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 37, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": 40, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 38, \"form\": \"千\", \"cpos\": \"CD\", \"pos\": null, \"head\": 39, \"deprel\": \"nummod\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 39, \"form\": \"层\", \"cpos\": \"M\", \"pos\": null, \"head\": 40, \"deprel\": \"clf\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 40, \"form\": \"饼\", \"cpos\": \"NN\", \"pos\": null, \"head\": 42, \"deprel\": \"nn\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 41, \"form\": \"等\", \"cpos\": \"ETC\", \"pos\": null, \"head\": 40, \"deprel\": \"etc\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 42, \"form\": \"面点\", \"cpos\": \"NN\", \"pos\": null, \"head\": 28, \"deprel\": \"dobj\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 43, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": 1, \"deprel\": \"punct\", \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}]\n",
      "  ],\n",
      "  \"semantic_dependencies\": [\n",
      "    [{\"id\": 1, \"form\": \"胡辣汤\", \"cpos\": \"NR\", \"pos\": null, \"head\": [13, 21], \"deprel\": [\"Agt\", \"Agt\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"由\", \"cpos\": \"P\", \"pos\": null, \"head\": [6, 11], \"deprel\": [\"mPrep\", \"mPrep\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"多\", \"cpos\": \"CD\", \"pos\": null, \"head\": [4], \"deprel\": [\"Quan\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"种\", \"cpos\": \"M\", \"pos\": null, \"head\": [6, 11], \"deprel\": [\"Qp\", \"Qp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"天然\", \"cpos\": \"JJ\", \"pos\": null, \"head\": [6], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"中草药\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"按\", \"cpos\": \"P\", \"pos\": null, \"head\": [11], \"deprel\": [\"mPrep\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"比例\", \"cpos\": \"NN\", \"pos\": null, \"head\": [9], \"deprel\": [\"Accd\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"配制\", \"cpos\": \"NN\", \"pos\": null, \"head\": [11], \"deprel\": [\"rAgt\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"的\", \"cpos\": \"DEC\", \"pos\": null, \"head\": [9], \"deprel\": [\"mAux\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"汤料\", \"cpos\": \"NN\", \"pos\": null, \"head\": [13], \"deprel\": [\"Accd\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"再\", \"cpos\": \"AD\", \"pos\": null, \"head\": [13], \"deprel\": [\"mFreq\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"加入\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"胡椒\", \"cpos\": \"NN\", \"pos\": null, \"head\": [13], \"deprel\": [\"Cont\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"和\", \"cpos\": \"CC\", \"pos\": null, \"head\": [16], \"deprel\": [\"mConj\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"辣椒\", \"cpos\": \"NN\", \"pos\": null, \"head\": [14], \"deprel\": [\"eCoo\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"又\", \"cpos\": \"AD\", \"pos\": null, \"head\": [21], \"deprel\": [\"mFreq\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"用\", \"cpos\": \"P\", \"pos\": null, \"head\": [20], \"deprel\": [\"mPrep\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"骨头\", \"cpos\": \"NN\", \"pos\": null, \"head\": [20], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 20, \"form\": \"汤\", \"cpos\": \"NN\", \"pos\": null, \"head\": [21], \"deprel\": [\"Matl\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 21, \"form\": \"做\", \"cpos\": \"VV\", \"pos\": null, \"head\": [13], \"deprel\": [\"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 22, \"form\": \"底料\", \"cpos\": \"JJ\", \"pos\": null, \"head\": [24], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 23, \"form\": \"的\", \"cpos\": \"DEC\", \"pos\": null, \"head\": [22], \"deprel\": [\"mAux\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 24, \"form\": \"胡辣汤\", \"cpos\": \"NN\", \"pos\": null, \"head\": [21], \"deprel\": [\"Prod\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 25, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [21], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 26, \"form\": \"其\", \"cpos\": \"PN\", \"pos\": null, \"head\": [27], \"deprel\": [\"Poss\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 27, \"form\": \"特点\", \"cpos\": \"NN\", \"pos\": null, \"head\": [28], \"deprel\": [\"Exp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 28, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": [21], \"deprel\": [\"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 29, \"form\": \"汤味\", \"cpos\": \"NN\", \"pos\": null, \"head\": [30], \"deprel\": [\"Exp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 30, \"form\": \"浓郁\", \"cpos\": \"VA\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 31, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": [30], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 32, \"form\": \"汤色\", \"cpos\": \"NN\", \"pos\": null, \"head\": [33], \"deprel\": [\"Exp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 33, \"form\": \"靓丽\", \"cpos\": \"VA\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 34, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": [30, 33], \"deprel\": [\"mPunc\", \"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 35, \"form\": \"汤汁\", \"cpos\": \"NN\", \"pos\": null, \"head\": [36], \"deprel\": [\"Exp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 36, \"form\": \"粘稠\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 37, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 38, \"form\": \"香辣可口\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 39, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [38], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 40, \"form\": \"十分\", \"cpos\": \"AD\", \"pos\": null, \"head\": [41], \"deprel\": [\"mDegr\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 41, \"form\": \"适合\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 42, \"form\": \"配合\", \"cpos\": \"VV\", \"pos\": null, \"head\": [41], \"deprel\": [\"dCont\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 43, \"form\": \"其它\", \"cpos\": \"DT\", \"pos\": null, \"head\": [44], \"deprel\": [\"Sco\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 44, \"form\": \"早点\", \"cpos\": \"NN\", \"pos\": null, \"head\": [42, 45], \"deprel\": [\"Datv\", \"Agt\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 45, \"form\": \"进餐\", \"cpos\": \"VV\", \"pos\": null, \"head\": [41, 42], \"deprel\": [\"dCont\", \"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 46, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}],\n",
      "    [{\"id\": 1, \"form\": \"目前\", \"cpos\": \"NT\", \"pos\": null, \"head\": [4, 5], \"deprel\": [\"Time\", \"Time\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [1], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"已经\", \"cpos\": \"AD\", \"pos\": null, \"head\": [4], \"deprel\": [\"mTime\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"发展\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"成为\", \"cpos\": \"VV\", \"pos\": null, \"head\": [4], \"deprel\": [\"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"河南\", \"cpos\": \"NR\", \"pos\": null, \"head\": [8], \"deprel\": [\"eCoo\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"及\", \"cpos\": \"CC\", \"pos\": null, \"head\": [8, 15], \"deprel\": [\"mConj\", \"mConj\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"陕西\", \"cpos\": \"NR\", \"pos\": null, \"head\": [11], \"deprel\": [\"Nmod\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"等\", \"cpos\": \"ETC\", \"pos\": null, \"head\": [8], \"deprel\": [\"mMaj\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"周边\", \"cpos\": \"NN\", \"pos\": null, \"head\": [11], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"省份\", \"cpos\": \"NN\", \"pos\": null, \"head\": [13], \"deprel\": [\"Aft\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"都\", \"cpos\": \"AD\", \"pos\": null, \"head\": [13], \"deprel\": [\"mRang\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"喜爱\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"和\", \"cpos\": \"CC\", \"pos\": null, \"head\": [15], \"deprel\": [\"mConj\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"知晓\", \"cpos\": \"NR\", \"pos\": null, \"head\": [17], \"deprel\": [\"Loc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"的\", \"cpos\": \"DEG\", \"pos\": null, \"head\": [15], \"deprel\": [\"mAux\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"小吃\", \"cpos\": \"NN\", \"pos\": null, \"head\": [18], \"deprel\": [\"Sco\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"之一\", \"cpos\": \"NN\", \"pos\": null, \"head\": [5], \"deprel\": [\"Clas\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": [5], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}],\n",
      "    [{\"id\": 1, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 2, \"form\": \"中国\", \"cpos\": \"NR\", \"pos\": null, \"head\": [3], \"deprel\": [\"Poss\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 3, \"form\": \"河南\", \"cpos\": \"NR\", \"pos\": null, \"head\": [7], \"deprel\": [\"Poss\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 4, \"form\": \"的\", \"cpos\": \"DEG\", \"pos\": null, \"head\": [3], \"deprel\": [\"mAux\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 5, \"form\": \"特色\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 6, \"form\": \"汤类\", \"cpos\": \"NN\", \"pos\": null, \"head\": [7], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 7, \"form\": \"食品\", \"cpos\": \"NN\", \"pos\": null, \"head\": [1], \"deprel\": [\"Clas\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 8, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [1], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 9, \"form\": \"被\", \"cpos\": \"LB\", \"pos\": null, \"head\": [10], \"deprel\": [\"mPrep\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 10, \"form\": \"大家\", \"cpos\": \"PN\", \"pos\": null, \"head\": [12], \"deprel\": [\"Aft\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 11, \"form\": \"所\", \"cpos\": \"MSP\", \"pos\": null, \"head\": [12], \"deprel\": [\"mPrep\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 12, \"form\": \"喜爱\", \"cpos\": \"VV\", \"pos\": null, \"head\": [1], \"deprel\": [\"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 13, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [12], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 14, \"form\": \"常\", \"cpos\": \"AD\", \"pos\": null, \"head\": [15], \"deprel\": [\"mFreq\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 15, \"form\": \"作为\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 16, \"form\": \"早餐\", \"cpos\": \"NN\", \"pos\": null, \"head\": [15], \"deprel\": [\"Clas\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 17, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [15], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 18, \"form\": \"其\", \"cpos\": \"PN\", \"pos\": null, \"head\": [19], \"deprel\": [\"Poss\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 19, \"form\": \"特点\", \"cpos\": \"NN\", \"pos\": null, \"head\": [20], \"deprel\": [\"Exp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 20, \"form\": \"是\", \"cpos\": \"VC\", \"pos\": null, \"head\": [15], \"deprel\": [\"eSucc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 21, \"form\": \"麻辣\", \"cpos\": \"JJ\", \"pos\": null, \"head\": [22], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 22, \"form\": \"鲜香\", \"cpos\": \"NN\", \"pos\": null, \"head\": [20], \"deprel\": [\"Clas\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 23, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 24, \"form\": \"营养\", \"cpos\": \"NN\", \"pos\": null, \"head\": [25], \"deprel\": [\"Desc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 25, \"form\": \"开胃\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 26, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [25], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 27, \"form\": \"适合\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 28, \"form\": \"搭配\", \"cpos\": \"VV\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 29, \"form\": \"油条\", \"cpos\": \"NN\", \"pos\": null, \"head\": [31], \"deprel\": [\"eCoo\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 30, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": [29], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 31, \"form\": \"包子\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 32, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": [31], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 33, \"form\": \"葱油\", \"cpos\": \"NN\", \"pos\": null, \"head\": [34], \"deprel\": [\"Nmod\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 34, \"form\": \"饼\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 35, \"form\": \"、\", \"cpos\": \"PU\", \"pos\": null, \"head\": [34], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 36, \"form\": \"锅盔\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 37, \"form\": \"，\", \"cpos\": \"PU\", \"pos\": null, \"head\": [36], \"deprel\": [\"mPunc\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 38, \"form\": \"千\", \"cpos\": \"CD\", \"pos\": null, \"head\": [39], \"deprel\": [\"Quan\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 39, \"form\": \"层\", \"cpos\": \"M\", \"pos\": null, \"head\": [40], \"deprel\": [\"Qp\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 40, \"form\": \"饼\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 41, \"form\": \"等\", \"cpos\": \"ETC\", \"pos\": null, \"head\": [40], \"deprel\": [\"mMaj\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 42, \"form\": \"面点\", \"cpos\": \"NN\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}, {\"id\": 43, \"form\": \"。\", \"cpos\": \"PU\", \"pos\": null, \"head\": [0], \"deprel\": [\"Root\"], \"lemma\": null, \"feats\": null, \"phead\": null, \"pdeprel\": null}]\n",
      "  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"胡辣汤由多种天然中草药按比例配制的汤料再加入胡椒和辣椒又用骨头汤做底料的胡辣汤，其特点是汤味浓郁、汤色靓丽、汤汁粘稠，香辣可口，十分适合配合其它早点进餐。目前，已经发展成为河南及陕西等周边省份都喜爱和知晓的小吃之一。是中国河南的特色汤类食品，被大家所喜爱，常作为早餐，其特点是麻辣鲜香，营养开胃，适合搭配油条、包子、葱油饼、锅盔，千层饼等面点。\"\n",
    "print(pipeline(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "Pipeline's output is a json dict. At any time, we can add extra pre/post-processing into the pipeline, including cleaning, custome dictionary etc. After that, we can run pipeline.save(\"mypipeline.json\") to save it. It is same as deep learning network, you can reconstruct its structure and save it. When you need it, just load it and run. That is one of the most important reasons I recommend HanLP to process Chinese articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train own model\n",
    "HanLP provides functions to train our own model, if one has his own dataset, he could train his own model on his data, and then predict his samples. The following is the sample code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanlp.components.tok import NgramConvTokenizer\n",
    "from hanlp.datasets.cws.sighan2005.msr import SIGHAN2005_MSR_TRAIN, SIGHAN2005_MSR_VALID, SIGHAN2005_MSR_TEST\n",
    "from hanlp.pretrained.word2vec import CONVSEG_W2V_NEWS_TENSITE_CHAR\n",
    "import tensorflow as tf\n",
    "tokenizer = NgramConvTokenizer()#net load\n",
    "save_dir = './'\n",
    "tokenizer.fit(SIGHAN2005_MSR_TRAIN,\n",
    "              SIGHAN2005_MSR_VALID,\n",
    "              save_dir,\n",
    "              word_embed={'class_name': 'HanLP>Word2VecEmbedding',\n",
    "                          'config': {\n",
    "                              'trainable': True,\n",
    "                              'filepath': CONVSEG_W2V_NEWS_TENSITE_CHAR,\n",
    "                              'expand_vocab': False,\n",
    "                              'lowercase': False,\n",
    "                          }},\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                                                 epsilon=1e-8, clipnorm=5),\n",
    "              epochs=5,\n",
    "              window_size=0,\n",
    "              metrics='f1',\n",
    "              weight_norm=True)#train model\n",
    "tokenizer.evaluate(SIGHAN2005_MSR_TEST, save_dir=save_dir)#evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "As we see the code above, HanLP provides dataset to download, so if you do not have suitable dataset, you can use it. Also, HanLP is based on Tensorflow 2.0 which has some problems at unexpected time. Luckily, HanLP developer still fix bug month by month, so I believe it will be more complete in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "HanLP is an up to date Chinese parsing toolkit. The version now is over 2.0 and its first develop platform is Java. So this guy has been updated for a long time and often utilizes state of art technology to complete it. That is the reason I really recommend it. We could not say it must be the best, it, however, could be good in time. Compared with jieba, another popular Chinese parsing tool, HanLP tries deep learning to parse and is quicker than jieba.\n",
    "So in a summary, I think HanLP has these good features:\n",
    "\n",
    "1. Really easy to install and deploy. You could easily use it.\n",
    "\n",
    "2. Enough funtions to use. Since it has trained many models, you mostly need one of them and other functions will help you to deal with articles.\n",
    "\n",
    "3. Up to date. Developer would cover famous nlp deep leeaning articles. What's more, it has established a forum to question, report bugs and communicate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Han He, HanLP: Han Language Processing, https://github.com/hankcs/HanLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
